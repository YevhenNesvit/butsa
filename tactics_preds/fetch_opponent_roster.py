import requests
from bs4 import BeautifulSoup
import json
import re
import time

# ==============================================================================
# 1. –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø
# ==============================================================================
TARGET_ROSTER_URL = "https://butsa.pro/roster/3469/" # <-- ID –∫–æ–º–∞–Ω–¥–∏ —Å—É–ø–µ—Ä–Ω–∏–∫–∞
MY_COOKIE = "36nvedj4e7r5g1hhbacd9r1oac" 

# –ù–ê–ó–í–ê –¢–£–†–ù–Ü–†–£ (–¢–æ—á–Ω–æ —è–∫ —É —Ç–∞–±–ª–∏—Ü—ñ!)
TARGET_TOURNAMENT = "–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–µ —Ç—É—Ä–Ω–∏—Ä—ã" 
# –ü—Ä–∏–∫–ª–∞–¥–∏: "–ß–µ–º–ø–∏–æ–Ω–∞—Ç —Å—Ç—Ä–∞–Ω—ã", "–ö—É–±–æ–∫ —Å—Ç—Ä–∞–Ω—ã", "–¢–æ–≤–∞—Ä–∏—â–µ—Å–∫–∏–µ –º–∞—Ç—á–∏"

# ==============================================================================
# 2. –§–£–ù–ö–¶–Ü–á
# ==============================================================================
def get_soup(url, cookie):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Cookie': f'PHPSESSID={cookie}'
    }
    try:
        r = requests.get(url, headers=headers)
        # –°–∞–π—Ç –≤—ñ–¥–¥–∞—î UTF-8 –≤ –º–µ—Ç–∞—Ç–µ–≥–∞—Ö, –∞–ª–µ —ñ–Ω–æ–¥—ñ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø–ª—É—Ç–∞—é—Ç—å. 
        # Beautiful Soup –∑–∞–∑–≤–∏—á–∞–π —Å–∞–º —Ä–æ–∑–±–∏—Ä–∞—î—Ç—å—Å—è, –∞–ª–µ –ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫:
        r.encoding = 'utf-8' 
        if r.status_code == 200:
            return BeautifulSoup(r.text, 'html.parser')
    except Exception as e:
        print(f"Error fetching {url}: {e}")
    return None

def parse_player_minutes(player_url, cookie, target_tournament):
    """
    –ó–Ω–∞—Ö–æ–¥–∏—Ç—å —Ç–∞–±–ª–∏—Ü—é "–¢–µ–∫—É—â–∏–π —Å–µ–∑–æ–Ω" —ñ —à—É–∫–∞—î —Ö–≤–∏–ª–∏–Ω–∏ –≤ –∑–∞–¥–∞–Ω–æ–º—É —Ç—É—Ä–Ω—ñ—Ä—ñ.
    """
    full_url = "https://butsa.pro" + player_url if not player_url.startswith("http") else player_url
    soup = get_soup(full_url, cookie)
    
    if not soup: return 0, "Error"

    # 1. –®—É–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–æ–∫ "–¢–µ–∫—É—â–∏–π —Å–µ–∑–æ–Ω"
    # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–æ—à—É–∫ –ø–æ —Ç–µ–∫—Å—Ç—É, –±–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –º–æ–∂–µ –±—É—Ç–∏ –≤–∫–ª–∞–¥–µ–Ω–æ—é
    season_header = soup.find(string=re.compile("–¢–µ–∫—É—â–∏–π —Å–µ–∑–æ–Ω"))
    
    if not season_header:
        # –Ø–∫—â–æ —Ä–∞–ø—Ç–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–∞ –Ω–µ–º–∞—î (–≥—Ä–∞–≤–µ—Ü—å –Ω–µ –≥—Ä–∞–≤ –Ω—ñ–¥–µ), –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ 0
        return 0, "No Season Data"

    # 2. –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–±–ª–∏–∂—á—É —Ç–∞–±–ª–∏—Ü—é –ü–Ü–°–õ–Ø —Ü—å–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞
    # .find_next('table') —à—É–∫–∞—î –Ω–∞—Å—Ç—É–ø–Ω–∏–π —Ç–µ–≥ table –≤ HTML-–¥–µ—Ä–µ–≤—ñ
    stats_table = season_header.find_next('table')
    
    if not stats_table:
        return 0, "No Table"

    # 3. –ü–∞—Ä—Å–∏–º–æ —Ä—è–¥–∫–∏ —Ü—ñ—î—ó —Ç–∞–±–ª–∏—Ü—ñ
    rows = stats_table.find_all('tr')
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ —ñ–Ω–¥–µ–∫—Å–∏ –∫–æ–ª–æ–Ω–æ–∫ (–ø—Ä–æ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫, —Ö–æ—á–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å—Ç–∞–±—ñ–ª—å–Ω–∞)
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç: [–ö–ª—É–±] [–°] [–¢—É—Ä–Ω–∏—Ä] [–ò–≥—Ä] [–ú–∏–Ω—É—Ç] ...
    # –Ü–Ω–¥–µ–∫—Å–∏ (0-based): 2 - –¢—É—Ä–Ω—ñ—Ä, 4 - –•–≤–∏–ª–∏–Ω–∏
    idx_tourn = 2
    idx_mins = 4

    for row in rows:
        cols = row.find_all('td')
        # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —ñ –∫–æ—Ä–æ—Ç–∫—ñ —Ä—è–¥–∫–∏
        if len(cols) <= idx_mins: continue
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –Ω–∞–∑–≤—É —Ç—É—Ä–Ω—ñ—Ä—É –≤ —Ä—è–¥–∫—É
        row_tourn_name = cols[idx_tourn].get_text(strip=True)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ —Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è (—ñ–≥–Ω–æ—Ä—É—î–º–æ —Ä–µ–≥—ñ—Å—Ç—Ä)
        if target_tournament.lower() in row_tourn_name.lower():
            # –ó–Ω–∞–π—à–ª–∏ –ø–æ—Ç—Ä—ñ–±–Ω–∏–π —Ç—É—Ä–Ω—ñ—Ä! –ë–µ—Ä–µ–º–æ —Ö–≤–∏–ª–∏–Ω–∏.
            minutes_text = cols[idx_mins].get_text(strip=True)
            
            # –ß–∏—Å—Ç–∏–º –≤—ñ–¥ —Å–º—ñ—Ç—Ç—è (–Ω–∞ –≤—Å—è–∫ –≤–∏–ø–∞–¥–æ–∫)
            clean_mins = re.sub(r'\D', '', minutes_text)
            
            if clean_mins:
                return int(clean_mins), row_tourn_name

    # –Ø–∫—â–æ –ø—Ä–æ–π—à–ª–∏ –≤—Å—é —Ç–∞–±–ª–∏—Ü—é "–¢–µ–∫—É—â–∏–π —Å–µ–∑–æ–Ω" —ñ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Ç—É—Ä–Ω—ñ—Ä
    return 0, "Not Played"

def scrape_roster_deep(url, cookie):
    print(f"üïµÔ∏è  –ê–Ω–∞–ª—ñ–∑ —Ä–æ—Å—Ç–µ—Ä–∞: {url}")
    soup = get_soup(url, cookie)
    if not soup: return []

    players = []
    # –®—É–∫–∞—î–º–æ —Ä—è–¥–∫–∏ –∑ –≥—Ä–∞–≤—Ü—è–º–∏. –ó–∞–∑–≤–∏—á–∞–π —Ü–µ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ /players/
    # –®—É–∫–∞—î–º–æ –≤—Å—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è, —â–æ –≤–µ–¥—É—Ç—å –Ω–∞ –ø—Ä–æ—Ñ—ñ–ª—å
    links = soup.find_all('a', href=re.compile(r'/players/\d+$'))
    
    print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(links)} –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –≥—Ä–∞–≤—Ü—ñ–≤. –ü–æ—á–∏–Ω–∞—î–º–æ —Å–∫–∞–Ω—É–≤–∞–Ω–Ω—è...")
    
    count = 0
    # –©–æ–± –Ω–µ –¥—É–±–ª—é–≤–∞—Ç–∏ –≥—Ä–∞–≤—Ü—ñ–≤ (—ñ–Ω–æ–¥—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –ø–æ–≤—Ç–æ—Ä—é—é—Ç—å—Å—è), –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ set
    processed_urls = set()

    for link in links:
        href = link.get('href', '')
        if href in processed_urls: continue
        processed_urls.add(href)
        
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –±–∞—Ç—å–∫—ñ–≤—Å—å–∫–∏–π —Ä—è–¥–æ–∫ (tr) –¥–ª—è —Ü—å–æ–≥–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è, —â–æ–± –≤–∑—è—Ç–∏ —Å—Ç–∞—Ç
        row = link.find_parent('tr')
        if not row: continue
        
        cols = row.find_all('td')
        if len(cols) < 10: continue # –¶–µ –Ω–µ —Ä—è–¥–æ–∫ —Ä–æ—Å—Ç–µ—Ä–∞

        try:
            name = link.get_text(strip=True)
            
            # –ü–æ–∑–∏—Ü—ñ—è (–ö–æ–ª–æ–Ω–∫–∞ 3)
            pos_text = cols[3].get_text(strip=True)
            clean_pos = [p.strip().upper() for p in pos_text.split('/')]
            
            # –°–∏–ª–∞ (–ö–æ–ª–æ–Ω–∫–∞ 5)
            p_val = int(re.sub(r'\D', '', cols[5].get_text(strip=True)))
            
            # –°—Ç–∞–º—ñ–Ω–∞ (–ö–æ–ª–æ–Ω–∫–∞ 7)
            s_val = int(re.sub(r'\D', '', cols[7].get_text(strip=True)))
            
            # –ú–æ—Ä–∞–ª—å (–ö–æ–ª–æ–Ω–∫–∞ 10)
            m_td = cols[10]
            m_title = m_td.get('title', '') or (m_td.find('img').get('title', '') if m_td.find('img') else '')
            m_match = re.search(r'\((\d+)\)', m_title)
            mor_val = int(m_match.group(1)) if m_match else 13

            # --- –ó–ê–•–Ü–î –í –ü–†–û–§–Ü–õ–¨ ---
            # –§–æ—Ä–º–∞—Ç—É—î–º–æ –≤–∏–≤—ñ–¥, —â–æ–± –±—É–ª–æ –∫—Ä–∞—Å–∏–≤–æ
            print(f"   [{count+1}/{len(links)}] {name[:20]:<20} ", end="")
            
            mins, found_tourn = parse_player_minutes(href, cookie, TARGET_TOURNAMENT)
            
            if mins > 0:
                print(f"-> {mins} —Ö–≤ ‚úÖ")
            else:
                print(f"-> 0 —Ö–≤") # –ù–µ –≥—Ä–∞–≤ –∞–±–æ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ

            players.append({
                "name": name,
                "pos": clean_pos,
                "power": p_val,
                "stamina": s_val,
                "morale": mor_val,
                "minutes": mins
            })
            count += 1
            time.sleep(0.2) # –ù–µ–≤–µ–ª–∏–∫–∞ –ø–∞—É–∑–∞

        except Exception as e:
            # print(f"–ü–æ–º–∏–ª–∫–∞: {e}") 
            continue

    return players

# ==============================================================================
# 3. –ó–ê–ü–£–°–ö
# ==============================================================================

final_data = scrape_roster_deep(TARGET_ROSTER_URL, MY_COOKIE)

if final_data:
    final_data.sort(key=lambda x: x['minutes'], reverse=True)
    
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢ (–¢—É—Ä–Ω–∏—Ä: {TARGET_TOURNAMENT}):")
    print(f"{'–Ü–º\'—è':<25} | {'–•–≤':<5} | {'–°–∏–ª–∞'}")
    print("-" * 45)
    for p in final_data:
        if p['minutes'] > 0:
            print(f"{p['name']:<25} | {p['minutes']:<5} | {p['power']}")

    with open('tactics_preds/opponent_roster.json', 'w', encoding='utf-8') as f:
        json.dump(final_data, f, ensure_ascii=False, indent=4)
    print(f"\nüíæ –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ!")
